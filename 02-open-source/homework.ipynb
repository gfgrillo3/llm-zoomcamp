{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b49c34d",
   "metadata": {},
   "source": [
    "# Homework: Open-Source LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db764f",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5507c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239104b4",
   "metadata": {},
   "source": [
    " ## Q1. Running Ollama with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a724077",
   "metadata": {},
   "source": [
    "What's the version of ollama client?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dae079",
   "metadata": {},
   "source": [
    "ollama version is 0.1.48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d9fbc7",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bb5399",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391b764",
   "metadata": {},
   "source": [
    "## Q2. Downloading an LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5da05",
   "metadata": {},
   "source": [
    "What's the content of the file related to gemma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed945e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81877b20",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e3b63",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38de89",
   "metadata": {},
   "source": [
    "## Q3. Running the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13cc7e0",
   "metadata": {},
   "source": [
    "Test the following prompt: \"10 * 10\". What's the answer?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acefcd1",
   "metadata": {},
   "source": [
    "The answer is: \"Sure, here is the model you requested:\n",
    "\n",
    "10 * 10\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35004f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd099c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f0207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daaf14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75195e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run -it --rm -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8095274-c9cd-4fd5-80d2-069fc951834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Homework: Open-Source LLMs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
